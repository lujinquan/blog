```
NETWORK_STATUS = True  # 判断状态变量
            try:
                req = s.get(test_url, headers=header,timeout=(3,7))
                if req.status_code == 200:
                    req=req
            except requests.exceptions.Timeout:
                global NETWORK_STATUS
                NETWORK_STATUS = False  # 请求超时改变状态
 
            if NETWORK_STATUS == False:
                #'''请求超时'''
                for i in range(1, 5):
                    print('请求超时，第%s次重复请求') % i
                    req = requests.post(url, headers=self.headers, data=data, timeout=(3,7))
                    if response.status_code == 200:
                        req=req
```
Python @retry装饰器的使用与实现案例(requests请求失败并重复请求)
在爬虫代码的编写中，requests请求网页的时候常常请求失败或错误，一般的操作是各种判断状态和超时，需要多次重试请求，这种情况下，如果想优雅的实现功能，可以学习下retrying包下的retry装饰器的使用

安装：pip install retrying

 

在@retry()装饰器中，比较重要的几个参数如下：

stop_max_attempt_number：在停止之前尝试的最大次数，最后一次如果还是有异常则会抛出异常，停止运行，默认为5次

wait_random_min：在两次调用方法停留时长，停留最短时间，默认为0,单位毫秒

wait_random_max：在两次调用方法停留时长，停留最长时间，默认为1000毫秒

retry_on_result：指定一个函数，如果指定的函数返回True，则重试，否则抛出异常退出

retry_on_exception: 指定一个函数，如果此函数返回指定异常，则会重试，如果不是指定的异常则会退出

这里只摘录几个常用的方法，想了解其他的方法，请自行查阅 

直接上例子：
```
# encoding:utf-8
import traceback
from retrying import retry
import requests
from user_agent import agert as ag
import random 
def _result(result):
    return result is None


def header(header):
    try:
        if header != None:
            header['User-Agent'] = random.choice(ag)
        else:
            header = {'User-Agent': random.choice(ag)}
        return header
    except Exception as e:
        traceback.print_exc(e) 
@retry(stop_max_attempt_number=5, wait_random_min=1000, wait_random_max=2000, retry_on_result=_result)
def My_Request_Get(url, headers=None):
        headers = header(headers)
        # with open('./proxy_txt', 'r') as f:
        #     proxy = f.readline()
        #     proxy = json.loads(proxy)
        # print proxy, type(proxy), '/*-'*10
        response = requests.get(url, headers=headers, timeout=6)
        if response.status_code != 200:
            raise requests.RequestException('my_request_get error!!!!')
        return response
```